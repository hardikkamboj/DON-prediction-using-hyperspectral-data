{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e6c2e0-1080-42fd-968e-b11cdd529cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.models import NeuralNetwork\n",
    "from src.data.data_loader import load_data\n",
    "from src.config.config import MODEL_PATHS, DEVICE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67662d42-8669-4e33-929f-b621587d4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper:\n",
    "    \"\"\"Wrapper class to make PyTorch model compatible with SHAP.\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X).to(DEVICE)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(X).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f77ea0-5058-4aae-a329-46bb2f860418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model, X, feature_names=None, sample_size=10):\n",
    "    \"\"\"\n",
    "    Analyze model using SHAP values.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        X: Input features\n",
    "        feature_names: List of feature names\n",
    "        sample_size: Number of samples to use for SHAP analysis\n",
    "    \"\"\"\n",
    "    # Create model wrapper for SHAP\n",
    "    model_wrapper = ModelWrapper(model)\n",
    "    \n",
    "    # Select random samples for background\n",
    "    if len(X) > sample_size:\n",
    "        background_inds = np.random.choice(len(X), sample_size, replace=False)\n",
    "        background_data = X[background_inds]\n",
    "    else:\n",
    "        background_data = X\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    print(\"\\nCreating SHAP explainer...\")\n",
    "    explainer = shap.DeepExplainer(model_wrapper, background_data)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    print(\"Calculating SHAP values...\")\n",
    "    shap_values = explainer.shap_values(X[:sample_size])\n",
    "    \n",
    "    # Create plots\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Summary plot\n",
    "    print(\"Creating summary plot...\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    shap.summary_plot(shap_values, X[:sample_size], \n",
    "                     feature_names=feature_names,\n",
    "                     plot_type=\"bar\",\n",
    "                     show=False)\n",
    "    plt.title(\"Feature Importance (SHAP Values)\")\n",
    "    \n",
    "    # Detailed SHAP values plot\n",
    "    print(\"Creating detailed SHAP plot...\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    shap.summary_plot(shap_values, X[:sample_size],\n",
    "                     feature_names=feature_names,\n",
    "                     show=False)\n",
    "    plt.title(\"Feature Impact on Predictions\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create dependence plots for top features\n",
    "    print(\"\\nCreating dependence plots for top features...\")\n",
    "    mean_abs_shap = np.abs(shap_values).mean(0)\n",
    "    top_features = np.argsort(-mean_abs_shap)[:5]  # Top 5 features\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, feature_idx in enumerate(top_features, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        feature_name = feature_names[feature_idx] if feature_names is not None else f\"Feature {feature_idx}\"\n",
    "        shap.dependence_plot(feature_idx, shap_values, X[:sample_size],\n",
    "                           feature_names=feature_names,\n",
    "                           show=False)\n",
    "        plt.title(f\"Dependence Plot: {feature_name}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return shap_values, mean_abs_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c711a77c-ff54-4af3-9633-bd77beb2efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Preprocess the input data using the saved scaler.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Input features\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed features\n",
    "    \"\"\"\n",
    "    # Load scaler\n",
    "    print(\"Loading scaler...\")\n",
    "    scaler = joblib.load(MODEL_PATHS['SCALER'])\n",
    "    \n",
    "    # Scale the input data\n",
    "    print(\"Normalizing input data...\")\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    return X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c2ba7f4-8d8c-4d79-bf7a-53a0a49c80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.models import NeuralNetwork\n",
    "from src.config.config import DEVICE\n",
    "\n",
    "def load_neural_network(model_path, input_dim=None):\n",
    "    \"\"\"\n",
    "    Load a saved model with its hyperparameters for prediction.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model file\n",
    "        input_dim (int, optional): Input dimension. If None, will be inferred from hyperparameters\n",
    "        \n",
    "    Returns:\n",
    "        model: Loaded neural network model\n",
    "        dict: Model hyperparameters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the saved model info\n",
    "        model_info = torch.load(model_path)\n",
    "        \n",
    "        if not isinstance(model_info, dict) or 'state_dict' not in model_info:\n",
    "            raise ValueError(\"Model file does not contain the expected format\")\n",
    "        \n",
    "        # Get hyperparameters\n",
    "        hyperparameters = model_info.get('hyperparameters', {})\n",
    "        \n",
    "        # Create model with the same architecture\n",
    "        if input_dim is None:\n",
    "            # Try to infer input_dim from the state dict\n",
    "            first_layer_weight = model_info['state_dict']['layer1.weight']\n",
    "            input_dim = first_layer_weight.size(1)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = NeuralNetwork(input_dim).to(DEVICE)\n",
    "        \n",
    "        # Update model architecture based on hyperparameters\n",
    "        if hyperparameters:\n",
    "            # Update layer sizes if they were optimized\n",
    "            if 'hidden_layer_0' in hyperparameters:\n",
    "                model.layer1 = torch.nn.Linear(input_dim, hyperparameters['hidden_layer_0']).to(DEVICE)\n",
    "                model.layer2 = torch.nn.Linear(hyperparameters['hidden_layer_0'], \n",
    "                                             hyperparameters['hidden_layer_1']).to(DEVICE)\n",
    "                model.layer3 = torch.nn.Linear(hyperparameters['hidden_layer_1'], \n",
    "                                             hyperparameters['hidden_layer_2']).to(DEVICE)\n",
    "                model.layer4 = torch.nn.Linear(hyperparameters['hidden_layer_2'], 1).to(DEVICE)\n",
    "            \n",
    "            # Update dropout if it was optimized\n",
    "            if 'dropout_rate' in hyperparameters:\n",
    "                model.dropout = torch.nn.Dropout(hyperparameters['dropout_rate'])\n",
    "        \n",
    "        # Load the state dict\n",
    "        model.load_state_dict(model_info['state_dict'])\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        return model, hyperparameters\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading model from {model_path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f62fd31-d4a2-4580-aaee-3945918fa1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"x_test.csv\")\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec182b72-6465-4930-a065-969669d7a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "feature_names = [f\"Wavelength_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# Analyze regular neural network\n",
    "print(\"\\nAnalyzing Regular Neural Network...\")\n",
    "regular_model = load_neural_network(MODEL_PATHS['NEURAL_NET'], X.shape[1])\n",
    "\n",
    "regular_shap_values, regular_importance = analyze_model(\n",
    "    regular_model, X, feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870fdce-135a-4847-b783-af29acb8a81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b7fb3-13d3-436c-8f19-7a56c32b502b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
